{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify SNP counts for mixed germline samples\n",
    "\n",
    "### Problem Statement\n",
    "The objective is to write software that classifies SNP counts for mixed germline samples (a minority\n",
    "sample mixed with a majority sample, e.g., through a contamination mechanism) and estimates the\n",
    "fraction of the minority sample. \n",
    "\n",
    "Despite counting and sequencing noise terms (and others), a best estimate of the minority sample\n",
    "fraction can be calculated across all alleles. \n",
    "\n",
    "The objective is then to identify which SNPs are likely to be informative (i.e., not matching the\n",
    "majority allele pattern) and calculate the minority sample fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-13\n",
      "hw_sample\n"
     ]
    }
   ],
   "source": [
    "today_date = datetime.date.today()\n",
    "print(today_date) # created files should have the current date, so you can find errors.  time is also helpful\n",
    "# I was thining about using the string in file name, and decided against it\n",
    "my_str = \"hw_sample*\"\n",
    "newstr = my_str.replace(\"*\", \"\")\n",
    "print(newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hw_sample_1.csv', 'hw_sample_0.csv', 'hw_sample_2.csv', 'hw_sample_7.csv', 'hw_sample_6.csv', 'hw_sample_4.csv', 'hw_sample_5.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['A', 'R', 'B', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob('hw_sample*') # first import any number of files\n",
    "print(filenames)\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in filenames ], sort = True)\n",
    "# this works, but does not do error handling\n",
    "# \"new\" columns added without comment\n",
    "# extra columns added if present\n",
    "\n",
    "combined_csv.allele.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>allele1</th>\n",
       "      <th>count</th>\n",
       "      <th>dbSNP.ID</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>rs10031144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>rs10031144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>rs10044327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "      <td>rs10044327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>rs10829589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  allele allele1 count    dbSNP.ID  test\n",
       "0      A     NaN   113  rs10031144   NaN\n",
       "1      R     NaN   162  rs10031144   NaN\n",
       "2      R     NaN   336  rs10044327   NaN\n",
       "3      A     NaN   353  rs10044327   NaN\n",
       "4      A     NaN    55  rs10829589   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()\n",
    "# remember to add file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(search_text):\n",
    "    combined_file = pd.DataFrame() # create empty data frame\n",
    "    filenames = glob.glob(search_text) # first import any number of files\n",
    "    if len(filenames) == 0: # if the file is blank, let people know\n",
    "        print(\"no files\")\n",
    "        print(\"no file created\")\n",
    "        exit(2) # end the program (this will exit python) fail fast!\n",
    "    else: \n",
    "        true_columns = sorted(['dbSNP.ID', 'allele', 'count' ]) # We know the true columns\n",
    "        for file in filenames:\n",
    "            test_file = pd.read_csv(file)\n",
    "            column_list = sorted(list(test_file.columns.values))\n",
    "            if len(column_list) == 3: # if there are three columns\n",
    "                if true_columns == column_list: # if they match true headers\n",
    "                    true_allele = sorted(['A', 'R'])\n",
    "                    if true_allele == sorted(list(test_file.allele.unique())):\n",
    "                        test_file['FileName'] = file # add the file name as a column\n",
    "                        try:\n",
    "                            # test if the count column really is numbers\n",
    "                            test_file['count'] = test_file['count'].astype(float)\n",
    "                            \n",
    "                            combined_file = combined_file.append(test_file,ignore_index=True) \n",
    "                            print(file, \"file added\") # this may be impractical if there are hundreds of files\n",
    "                        except ValueError:\n",
    "                            print(file, \"count column includes non-numbers\")\n",
    "                        \n",
    "                    else:\n",
    "                        print(file, \"wrong allele list\", test_file.allele.unique())\n",
    "                        # Another source of error could be that the file was set up wrong.  \n",
    "                        # This is only one way it could be wrong.  Another could be in SNP name and Count NAN\n",
    "                else:\n",
    "                    print(file, \"columns do not match\", column_list)\n",
    "            else:\n",
    "                print(file, \"too many columns\", column_list)\n",
    "        #export to csv\n",
    "        new_file_name = str(datetime.date.today()) + \"combined_file.csv\"\n",
    "        combined_file.to_csv(new_file_name, index=False) # save the file before doing calculations\n",
    "        print(new_file_name,\" file created\")\n",
    "    return(combined_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_sample_1.csv file added\n",
      "hw_sample_0.csv file added\n",
      "hw_sample_2.csv file added\n",
      "hw_sample_7.csv count column includes non-numbers\n",
      "hw_sample_6.csv wrong allele list ['B' 'R']\n",
      "hw_sample_4.csv too many columns ['allele1', 'count', 'dbSNP.ID', 'test']\n",
      "hw_sample_5.csv columns do not match ['allele1', 'count', 'dbSNP.ID']\n",
      "2020-02-13combined_file.csv  file created\n"
     ]
    }
   ],
   "source": [
    "file1 = combine_files('hw_sample*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dbSNP.ID     object\n",
       "allele       object\n",
       "count       float64\n",
       "FileName     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_informative(data_frame):\n",
    "    # spread the columns (make the two alleles each their own column)\n",
    "    stacked_file = data_frame.pivot_table(index=['dbSNP.ID', 'FileName'], columns='allele', values='count') \n",
    "    stacked_file = stacked_file.reset_index() # I don't like working with two columns as \"index\"\n",
    "    stacked_file = stacked_file.fillna(0) # if either A or R had no values, we fill them with zero\n",
    "    # caluclate the frequency of A allele, R is not needed as freq_A + freq_R = 1\n",
    "    stacked_file['freq_A'] = stacked_file['A']/(stacked_file['R']+ stacked_file['A'])\n",
    "    # we want those with low A and with low R.  Subtracting freq_A from 0.5 gets us low A\n",
    "    # using the absolute value (abs) gives us both low R and low A\n",
    "    stacked_file['abs_A'] = abs(stacked_file['freq_A'] - 0.5)\n",
    "    # we want to label those with frequency (A or R) > 0.8 as informative\n",
    "    stacked_file.loc[stacked_file.abs_A > 0.3, 'informative'] = 'True' \n",
    "    stacked_file.loc[stacked_file.abs_A <= 0.3, 'informative'] = 'False' \n",
    "    # there are some SNP's with very low counts, possibly due to read error\n",
    "    # I chose to ignore those with counts less than 2% as uninformative\n",
    "    stacked_file.loc[stacked_file.abs_A > 0.48, 'informative'] = 'False'\n",
    "    new_file_name = str(datetime.date.today()) + \"calculations_file.csv\"\n",
    "    stacked_file.to_csv(new_file_name, index = False) # save the file before doing calculations\n",
    "    print(new_file_name,\" file created\")\n",
    "    # the exercise said to create a file with orig file name, SNP and informative-ness\n",
    "    output_1 = stacked_file[['FileName','dbSNP.ID', 'informative' ]]\n",
    "    output_1.to_csv('output_1.csv', index = False)\n",
    "    return(stacked_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-13calculations_file.csv  file created\n",
      "['dbSNP.ID', 'FileName', 'A', 'R', 'freq_A', 'abs_A', 'informative']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>allele</th>\n",
       "      <th>dbSNP.ID</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>freq_A</th>\n",
       "      <th>abs_A</th>\n",
       "      <th>informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rs10031144</td>\n",
       "      <td>hw_sample_0.csv</td>\n",
       "      <td>63.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>rs10031144</td>\n",
       "      <td>hw_sample_1.csv</td>\n",
       "      <td>113.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.410909</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rs10031144</td>\n",
       "      <td>hw_sample_2.csv</td>\n",
       "      <td>99.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rs10044327</td>\n",
       "      <td>hw_sample_0.csv</td>\n",
       "      <td>241.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.481038</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rs10044327</td>\n",
       "      <td>hw_sample_1.csv</td>\n",
       "      <td>353.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.512337</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "allele    dbSNP.ID         FileName      A      R    freq_A     abs_A  \\\n",
       "0       rs10031144  hw_sample_0.csv   63.0   85.0  0.425676  0.074324   \n",
       "1       rs10031144  hw_sample_1.csv  113.0  162.0  0.410909  0.089091   \n",
       "2       rs10031144  hw_sample_2.csv   99.0  112.0  0.469194  0.030806   \n",
       "3       rs10044327  hw_sample_0.csv  241.0  260.0  0.481038  0.018962   \n",
       "4       rs10044327  hw_sample_1.csv  353.0  336.0  0.512337  0.012337   \n",
       "\n",
       "allele informative  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = label_informative(file1)\n",
    "\n",
    "print(list(test1.columns))\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_sample_fraction(data_frame):\n",
    "    contam_data = data_frame.loc[data_frame['informative'] == 'True']\n",
    "    contam_data['contam'] = abs(contam_data['abs_A'] - 0.5)\n",
    "    contam = contam_data.loc[:,['dbSNP.ID','FileName', 'contam']]\n",
    "    minor_sample_fraction = contam.groupby(['FileName']).mean()\n",
    "    return(minor_sample_fraction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>allele</th>\n",
       "      <th>contam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hw_sample_0.csv</td>\n",
       "      <td>0.049034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hw_sample_1.csv</td>\n",
       "      <td>0.075821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hw_sample_2.csv</td>\n",
       "      <td>0.092295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "allele             contam\n",
       "FileName                 \n",
       "hw_sample_0.csv  0.049034\n",
       "hw_sample_1.csv  0.075821\n",
       "hw_sample_2.csv  0.092295"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = find_minority_sample_fraction(test1)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
